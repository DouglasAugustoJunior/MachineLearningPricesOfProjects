# -*- coding: utf-8 -*-
"""Machine Learning - Preços de projeto.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1u_pDVlGHCxClwT-YjCd8dMK4QWe9HvfI

# LinearSVC
"""

import pandas as pd                                  # biblioteca que permite a leitura de CSVs
from sklearn.svm import LinearSVC                    # Importa a biblioteca do estimador
from sklearn.metrics import accuracy_score           # Importa a biblioteca de acurácia
from sklearn.model_selection import train_test_split # Usado para separar os dados de treino dos de teste
from sklearn.multiclass import OneVsRestClassifier   # Usado para remover aviso de iterações do estimador colocando o max nas iterações
import seaborn as sns                                # biblioteca para exibir resultados plotados em 2D, gráficos
import numpy as np                                   # Gera números para comparar
import matplotlib.pyplot as plt                      # Plotar dados no gráfico de forma mais refinada

# link do arquivo CSV
uri = "https://gist.githubusercontent.com/guilhermesilveira/1b7d5475863c15f484ac495bd70975cf/raw/16aff7a0aee67e7c100a2a48b676a2d2d142f646/projects.csv"

dados = pd.read_csv(uri) # Lê o arquivo CSV
dados.head() # Exibe os 5 primeiros
dados.shape  # Exibe o total de elementos no arquivo

mapa = { 
    'expected_hours' : 'horas_esperadas',
    'price'          : 'preco',
    'unfinished'     : 'nao_finalizado'
} # Novos nomes das colunas dentro de um dicionário {}

dados = dados.rename(columns = mapa) # Renomeia as colunas do CSV

troca = {
    0 : 1,
    1 : 0
} # Vai inverter a coluna de "nao_finalizados" para criar a "finalizados"

dados['finalizado'] = dados.nao_finalizado.map(troca) # cria a coluna finalizados
#dados.tail() # Exibe o 'rabo' da lista

x = dados[['horas_esperadas', 'preco']] # Pega colunas referente ao X
y = dados['finalizado'] # Pega colunas referente ao Y

SEED = 20 # N° Inicial da posição que será usada para separar o CSV em vetores, remove a aleatoriedade
np.random.seed(SEED) # Passa o padrão para aleatoriedade

# Popula as 4 variáveis informando que o teste terá 25% dos dados e a semente será o 20, para não ser radomico
train_x, teste_x, train_y, teste_y =train_test_split(x,
                                                     y,
                                                     test_size =0.25,
                                                     stratify = y) # stratify estratifica os dados para dividir proporcionalmente

print("Treinaremos com %d elementos e testaremos com %d elementos." % (len(train_x), len(teste_x)))

estimador = OneVsRestClassifier(LinearSVC(max_iter=1000)) # Instância do estimador

#___________________________________________________

estimador.fit(train_x, train_y) # Ensina o estimador com os dados e as classes desses dados

previsoes = estimador.predict(teste_x) # Prediz oque cada item da lista é

acuracia = accuracy_score(teste_y, previsoes) * 100 # Valida a acurácia
print("A acurácia foi de: %.2f%%" % acuracia)

# Algoritmo base, chute tudo 1
baseline = np.ones(540) # Gera lista com todos os 1 para testar o chute
acuraciabaseline = accuracy_score(teste_y, baseline) * 100
print("A acurácia da baseline foi de: %.2f%%" % acuraciabaseline)

sns.scatterplot(x="horas_esperadas", y="preco", data=dados) # Monta o gráfico padrão, mesma cor, x e y

sns.scatterplot(x="horas_esperadas", y="preco", hue="finalizado", data=dados) # Gráfico padrão, em duas cores o finalizado, X e Y

sns.relplot(x="horas_esperadas", y="preco", col="finalizado", data=dados) # Separa os resultados da coluna 'finalizado' em gráficos diferentes

sns.relplot(x="horas_esperadas", y="preco", hue="finalizado", col="finalizado", data=dados) # Separa em colunas e cores diferentes

sns.scatterplot(x="horas_esperadas", y="preco", hue=teste_y, data=teste_x) # Gráfico padrão, em duas cores o finalizado, X e Y do teste_x

#_____________decision boundary/ Curva de decisão______________________________ 
# Pega a minima e máxima horizontal
x_min = teste_x.horas_esperadas.min()
x_max = teste_x.horas_esperadas.max()

# Pega a minima e máxima vertical
y_min = teste_x.preco.min()
y_max = teste_x.preco.max()

print('X min:', x_min,'X max:', x_max,'Y min:', y_min,'Y max:', y_max)

pixels = 100 # Tamanho do quadro

eixo_x = np.arange(x_min, x_max, (x_max - x_min)/ pixels) # Tamanho dos pontos
eixo_y = np.arange(y_min, y_max, (y_max - y_min)/ pixels) # Tamanho dos pontos

xx, yy = np.meshgrid(eixo_x, eixo_y) # Mescla os eixos

pontos = np.c_[xx.ravel(), yy.ravel()] # Concatena e gera os pontos

Z = estimador.predict(pontos) # Predição dos pontos do quadro
Z = Z.reshape(xx.shape) # Redimensiona o array para 100x100

plt.contourf(xx, yy, Z, alpha=0.3) #fundo do gráfico com a predição (errada)
plt.scatter(teste_x.horas_esperadas, teste_x.preco, c=teste_y, s=1) # pontos do gráfico

"""# Somente com SVC"""

import pandas as pd                                  # biblioteca que permite a leitura de CSVs
from sklearn.svm import SVC                          # Importa a biblioteca do estimador não linear
from sklearn.metrics import accuracy_score           # Importa a biblioteca de acurácia
from sklearn.model_selection import train_test_split # Usado para separar os dados de treino dos de teste
import seaborn as sns                                # biblioteca para exibir resultados plotados em 2D, gráficos
import numpy as np                                   # Gera números para comparar
import matplotlib.pyplot as plt                      # Plotar dados no gráfico de forma mais refinada

# link do arquivo CSV
uri = "https://gist.githubusercontent.com/guilhermesilveira/1b7d5475863c15f484ac495bd70975cf/raw/16aff7a0aee67e7c100a2a48b676a2d2d142f646/projects.csv"

dados = pd.read_csv(uri) # Lê o arquivo CSV
dados.head() # Exibe os 5 primeiros
dados.shape  # Exibe o total de elementos no arquivo

mapa = { 
    'expected_hours' : 'horas_esperadas',
    'price'          : 'preco',
    'unfinished'     : 'nao_finalizado'
} # Novos nomes das colunas dentro de um dicionário {}

dados = dados.rename(columns = mapa) # Renomeia as colunas do CSV

troca = {
    0 : 1,
    1 : 0
} # Vai inverter a coluna de "nao_finalizados" para criar a "finalizados"

dados['finalizado'] = dados.nao_finalizado.map(troca) # cria a coluna finalizados
#dados.tail() # Exibe o 'rabo' da lista

x = dados[['horas_esperadas', 'preco']] # Pega colunas referente ao X
y = dados['finalizado'] # Pega colunas referente ao Y

SEED = 5 # N° Inicial da posição que será usada para separar o CSV em vetores, remove a aleatoriedade
np.random.seed(SEED) # Passa o padrão para aleatoriedade

# Popula as 4 variáveis informando que o teste terá 25% dos dados e a semente será o 20, para não ser radomico
train_x, teste_x, train_y, teste_y =train_test_split(x,
                                                     y,
                                                     test_size =0.25,
                                                     stratify = y) # stratify estratifica os dados para dividir proporcionalmente

print("Treinaremos com %d elementos e testaremos com %d elementos." % (len(train_x), len(teste_x)))
print('___________________________________________________')
estimador = SVC() # Instância do estimador

#___________________________________________________

estimador.fit(train_x, train_y) # Ensina o estimador com os dados e as classes desses dados

previsoes = estimador.predict(teste_x) # Prediz oque cada item da lista é

acuracia = accuracy_score(teste_y, previsoes) * 100 #valida a acurácia
print("A acurácia foi de: %.2f%%" % acuracia)
print('___________________________________________________')

# Algoritmo base, chute tudo 1
baseline = np.ones(540) # Gera lista com todos os 1 para testar o chute
acuraciabaseline = accuracy_score(teste_y, baseline) * 100
print("A acurácia da baseline foi de: %.2f%%" % acuraciabaseline)
print('___________________________________________________')

#_____________decision boundary/ Curva de decisão______________________________ 
# Pega a minima e máxima horizontal
x_min = teste_x.horas_esperadas.min()
x_max = teste_x.horas_esperadas.max()

# Pega a minima e máxima vertical
y_min = teste_x.preco.min()
y_max = teste_x.preco.max()

pixels = 100 # Tamanho do quadro

eixo_x = np.arange(x_min, x_max, (x_max - x_min)/ pixels) # Tamanho dos pontos
eixo_y = np.arange(y_min, y_max, (y_max - y_min)/ pixels) # Tamanho dos pontos

xx, yy = np.meshgrid(eixo_x, eixo_y) # Mescla os eixos

pontos = np.c_[xx.ravel(), yy.ravel()] # Concatena e gera os pontos

Z = estimador.predict(pontos) # Predição dos pontos do quadro
Z = Z.reshape(xx.shape) # Redimensiona o array para 100x100

plt.contourf(xx, yy, Z, alpha=0.3) #fundo do gráfico com a predição (errada)
plt.scatter(teste_x.horas_esperadas, teste_x.preco, c=teste_y, s=1) # pontos do gráfico

"""# StandardScaler"""

from sklearn.preprocessing import StandardScaler     # Préprocessamento dos dados, usado para deixar os valores na mesma faixa e evitar alterações por diferentes faixas nos dados
import pandas as pd                                  # biblioteca que permite a leitura de CSVs
from sklearn.svm import SVC                          # Importa a biblioteca do estimador não linear
from sklearn.metrics import accuracy_score           # Importa a biblioteca de acurácia
from sklearn.model_selection import train_test_split # Usado para separar os dados de treino dos de teste
import seaborn as sns                                # biblioteca para exibir resultados plotados em 2D, gráficos
import numpy as np                                   # Gera números para comparar
import matplotlib.pyplot as plt                      # Plotar dados no gráfico de forma mais refinada

# link do arquivo CSV
uri = "https://gist.githubusercontent.com/guilhermesilveira/1b7d5475863c15f484ac495bd70975cf/raw/16aff7a0aee67e7c100a2a48b676a2d2d142f646/projects.csv"

dados = pd.read_csv(uri) # Lê o arquivo CSV
dados.head() # Exibe os 5 primeiros
dados.shape  # Exibe o total de elementos no arquivo

mapa = { 
    'expected_hours' : 'horas_esperadas',
    'price'          : 'preco',
    'unfinished'     : 'nao_finalizado'
} # Novos nomes das colunas dentro de um dicionário {}

dados = dados.rename(columns = mapa) # Renomeia as colunas do CSV

troca = {
    0 : 1,
    1 : 0
} # Vai inverter a coluna de "nao_finalizados" para criar a "finalizados"

dados['finalizado'] = dados.nao_finalizado.map(troca) # cria a coluna finalizados
#dados.tail() # Exibe o 'rabo' da lista

x = dados[['horas_esperadas', 'preco']] # Pega colunas referente ao X
y = dados['finalizado'] # Pega colunas referente ao Y

SEED = 5 # N° Inicial da posição que será usada para separar o CSV em vetores, remove a aleatoriedade
np.random.seed(SEED) # Passa o padrão para aleatoriedade

# Popula as 4 variáveis informando que o teste terá 25% dos dados e a semente será o 20, para não ser radomico
raw_train_x, raw_teste_x, train_y, teste_y =train_test_split(x,
                                                     y,
                                                     test_size =0.25,
                                                     stratify = y) # stratify estratifica os dados para dividir proporcionalmente

print("Treinaremos com %d elementos e testaremos com %d elementos." % (len(train_x), len(teste_x)))
print('___________________________________________________')

scaler = StandardScaler() # cria o escalador
scaler.fit(raw_train_x) # Passa os valores a serem escalados na mesma faixa, nova escala aqui
train_x = scaler.transform(raw_train_x) # atribui ao treino_X a nova escala gerado no cru_treino_x
teste_x = scaler.transform(raw_teste_x) # atribui ao teste_X a nova escala

estimador = SVC() # Instância do estimador

#___________________________________________________

estimador.fit(train_x, train_y) # Ensina o estimador com os dados e as classes desses dados

previsoes = estimador.predict(teste_x) # Prediz oque cada item da lista é

acuracia = accuracy_score(teste_y, previsoes) * 100 # Valida a acurácia
print("A acurácia foi de: %.2f%%" % acuracia)
print('___________________________________________________')

# Algoritmo base, chute tudo 1
baseline = np.ones(540) # Gera lista com todos os 1 para testar o chute
acuraciabaseline = accuracy_score(teste_y, baseline) * 100
print("A acurácia da baseline foi de: %.2f%%" % acuraciabaseline)
print('___________________________________________________')

#_____________decision boundary/ Curva de decisão______________________________ 

data_x = teste_x[:,0] # : todos os registros, coluna 0 (horas_esperadas)
data_y = teste_x[:,1] # : todos os registros, coluna 1 (preco)


# Pega a minima e máxima horizontal
x_min = data_x.min()
x_max = data_x.max()

# Pega a minima e máxima vertical
y_min = data_y.min()
y_max = data_y.max()

pixels = 100 # Tamanho do quadro

eixo_x = np.arange(x_min, x_max, (x_max - x_min)/ pixels) # Tamanho dos pontos
eixo_y = np.arange(y_min, y_max, (y_max - y_min)/ pixels) # Tamanho dos pontos

xx, yy = np.meshgrid(eixo_x, eixo_y) # Mescla os eixos

pontos = np.c_[xx.ravel(), yy.ravel()] # Concatena e gera os pontos

Z = estimador.predict(pontos) # Predição dos pontos do quadro
Z = Z.reshape(xx.shape) # Redimensiona o array para 100x100

plt.contourf(xx, yy, Z, alpha=0.3) #fundo do gráfico com a predição (certa)
plt.scatter(data_x, data_y, c=teste_y, s=1) # pontos do gráfico